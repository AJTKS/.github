## 알잘딱깔센 - 나만의 음악 추천서비스
#### 2024 Spring YAICON TEAM

[AJTKS Website](https://ajtks.site)

<img width="1512" alt="image" src="https://github.com/AJTKS/.github/assets/115399447/fb8230d5-b709-474f-a0e5-765014663e0a">
<img width="1509" alt="image" src="https://github.com/AJTKS/.github/assets/115399447/1db90114-b7ca-4814-94bd-8c0aa6137e4d">


## Repository 

- [Client](https://github.com/AJTKS/AJTKS-client) (public)
- [Server](https://github.com/AJTKS/AJTKS-server) (private)
- [MU-LLAMA3](https://github.com/AJTKS/MU-LLaMA3) (public)

## Reference Papers
- [Audio Spectrogram Transformer(AST)](https://arxiv.org/abs/2104.01778) | [Github](https://github.com/YuanGongND/ast)
- [Listen, Think, and Understand(LTU)](https://openreview.net/pdf?id=nBZBPXdJlC) | [Github](https://github.com/YuanGongND/ltu)
- [Music Emotion Maps in Arousal-Valence Space](https://www.researchgate.net/publication/307909024_Music_Emotion_Maps_in_Arousal-Valence_Space)
- [MERT: Acoustic Music Understanding Model with Large-Scale Self-Supervised Training](https://arxiv.org/pdf/2306.00107) | [Github](https://github.com/yizhilll/MERT)
- [Audio Signal Mapping into Spectrogram-Based Images for Deep Learning Applications](10.1109/INFOTEH51037.2021.9400698)
- [Music Understanding LLaMA: Advancing Text-to-Music Generation with Question Answering and Captioning](https://arxiv.org/abs/2308.11276) | [Github](https://github.com/shansongliu/MU-LLaMA)

## Team Members

### 서정민
- `Team Leader`
- Listen, Think, and Understand `Paper Review`

### 전희재
- MERT: Acoustic Music Understanding Model with Large-Scale Self-Supervised Training `Paper Review`

### 조현진
- LLark: A Multimodal Instruction-Following Language Model for Music `Paper Review`

### 박승호
- Listen, Think, and Understand `Paper Review`

### 김주의
- LLark: A Multimodal Instruction-Following Language Model for Music `Paper Review`

### 박준형
- MERT: Acoustic Music Understanding Model with Large-Scale Self-Supervised Training `Paper Review`
